{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wkumagai/ResearchGraphOutput/blob/main/notebook/research_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxgAaE-nM19j"
      },
      "source": [
        "# Research Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_YtVftYFsT1"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auto-res/researchgraph/blob/main/notebook/research_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHd72lYmFsT1"
      },
      "source": [
        "- https://github.com/auto-res/researchgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFcF0FuNFsT2",
        "outputId": "f5495211-f117-4167-82d6-60e16ccba69d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.org (18.160.213.101)] [\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,972 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,773 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,134 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,085 kB]\n",
            "Get:16 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [70.9 kB]\n",
            "Err:16 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages\n",
            "  File has unexpected size (70320 != 70882). Mirror sync in progress? [IP: 18.160.213.101 443]\n",
            "  Hashes of expected file:\n",
            "   - Filesize:70882 [weak]\n",
            "   - SHA512:3847dded1c5d1d1e8fcda748e716573695c8172b6bc3a608916183b891a0de8f3265c970e5599e5a8ff81f08faaf343437fa41d1e61eb8b89cf2f8ab1255087d\n",
            "   - SHA256:503ba84d5aa4a4bcbe214dee215d515ee3e463b84887be2b4cf8ab3ec786c79f\n",
            "   - MD5Sum:40e503aa8292423c9e7128bceb7c1d5f [weak]\n",
            "  Release file created at: Thu, 03 Apr 2025 01:15:59 +0000\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,685 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,802 kB]\n",
            "Fetched 27.4 MB in 10s (2,676 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "E: Failed to fetch https://cloud.r-project.org/bin/linux/ubuntu/jammy-cran40/Packages.gz  File has unexpected size (70320 != 70882). Mirror sync in progress? [IP: 18.160.213.101 443]\n",
            "   Hashes of expected file:\n",
            "    - Filesize:70882 [weak]\n",
            "    - SHA512:3847dded1c5d1d1e8fcda748e716573695c8172b6bc3a608916183b891a0de8f3265c970e5599e5a8ff81f08faaf343437fa41d1e61eb8b89cf2f8ab1255087d\n",
            "    - SHA256:503ba84d5aa4a4bcbe214dee215d515ee3e463b84887be2b4cf8ab3ec786c79f\n",
            "    - MD5Sum:40e503aa8292423c9e7128bceb7c1d5f [weak]\n",
            "   Release file created at: Thu, 03 Apr 2025 01:15:59 +0000\n",
            "E: Some index files failed to download. They have been ignored, or old ones used instead.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install -y \\\n",
        "    texlive-base \\\n",
        "    texlive-latex-recommended \\\n",
        "    texlive-fonts-recommended \\\n",
        "    texlive-latex-extra \\\n",
        "    texlive-science \\\n",
        "    chktex \\\n",
        "    locales && \\\n",
        "    rm -rf /var/lib/apt/lists/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ylw_kTWvYjwv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Please register the secret with the name below in google colab.\n",
        "\n",
        "# https://platform.openai.com/settings/organization/api-keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "# https://app.devin.ai/settings/api-keys\n",
        "os.environ[\"DEVIN_API_KEY\"] = userdata.get(\"DEVIN_API_KEY\")\n",
        "# https://www.firecrawl.dev/app/api-keys\n",
        "os.environ[\"FIRE_CRAWL_API_KEY\"] = userdata.get(\"FIRE_CRAWL_API_KEY\")\n",
        "# https://docs.github.com/ja/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#fine-grained-personal-access-token-%E3%81%AE%E4%BD%9C%E6%88%90\n",
        "os.environ[\"GITHUB_PERSONAL_ACCESS_TOKEN\"] = userdata.get(\"GITHUB_PERSONAL_ACCESS_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIwcbxvOLg6k",
        "outputId": "cab6486b-69e6-477f-a00c-270c9c2346c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'researchgraph'...\n",
            "remote: Enumerating objects: 4913, done.\u001b[K\n",
            "remote: Counting objects: 100% (529/529), done.\u001b[K\n",
            "remote: Compressing objects: 100% (291/291), done.\u001b[K\n",
            "remote: Total 4913 (delta 280), reused 244 (delta 232), pack-reused 4384 (from 3)\u001b[K\n",
            "Receiving objects: 100% (4913/4913), 33.23 MiB | 28.64 MiB/s, done.\n",
            "Resolving deltas: 100% (2701/2701), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/auto-res/researchgraph.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "EvOT9qPTNJY9"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install uv\n",
        "%cd /content/researchgraph\n",
        "!uv pip compile pyproject.toml > requirements.txt\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0zS4VQzJg6Co"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/researchgraph/src')\n",
        "\n",
        "from researchgraph.research_graph import ResearchGraph\n",
        "\n",
        "import logging\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='[%(levelname)s] %(name)s: %(message)s'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGMSLhvMNLMy"
      },
      "source": [
        "### Research Graph settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "67WLzWzUZNtM"
      },
      "outputs": [],
      "source": [
        "# Please set up a repository to store your research results.\n",
        "# The repository you set up must be one that can be controlled using a personal access token.\n",
        "repository = \"auto-res2/auto-research\"\n",
        "\n",
        "# Directory to save results\n",
        "save_dir = \"/content/researchgraph/data\"\n",
        "# web site to get the paper\n",
        "scrape_urls = [\n",
        "    \"https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title\",\n",
        "    \"https://icml.cc/virtual/2024/papers.html?filter=title\",\n",
        "    \"https://iclr.cc/virtual/2024/papers.html?filter=title\",\n",
        "]\n",
        "# Number of papers to obtain ideas to be incorporated into the base paper\n",
        "add_paper_num = 3\n",
        "# Maximum number of times the experimental code can be modified\n",
        "max_code_fix_iteration = 3\n",
        "\n",
        "research_graph = ResearchGraph(\n",
        "    save_dir=save_dir,\n",
        "    scrape_urls=scrape_urls,\n",
        "    add_paper_num=add_paper_num,\n",
        "    repository=repository,\n",
        "    max_code_fix_iteration=max_code_fix_iteration,\n",
        ").build_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lBy7LIIgMA_6"
      },
      "outputs": [],
      "source": [
        "# Please set what kind of research you will be conducting.\n",
        "input_data = {\n",
        "    \"queries\": [\"Bayesian optimization\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAsRiEa4M9XB"
      },
      "source": [
        "### Executing Research Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sgmkEr3YL2ow",
        "outputId": "6f6bfa90-5664-4779-d85d-21c264d77a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph]                Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: ---RetrievePaperSubgraph---\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._base_web_scrape_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Executing FireCrawl API scraping...\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://icml.cc/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://iclr.cc/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[ERROR] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Attempt 1 failed with HTTP error: The read operation timed out\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Retrying in 1 seconds...\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 500 Internal Server Error\"\n",
            "[ERROR] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Attempt 2 failed with HTTP error: Server error '500 Internal Server Error' for url 'https://api.firecrawl.dev/v1/scrape'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Retrying in 2 seconds...\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 500 Internal Server Error\"\n",
            "[ERROR] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Attempt 3 failed with HTTP error: Server error '500 Internal Server Error' for url 'https://api.firecrawl.dev/v1/scrape'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Retrying in 4 seconds...\n",
            "[ERROR] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Error with FireCrawl API: Max retries reached. Scrape URL API request failed.\n",
            "[ERROR] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: FireCrawl API failed - returning empty results\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._base_web_scrape_node] End    Execution Time: 118.9762 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_paper_title_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_paper_title_node] End    Execution Time: 34.3400 seconds\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: check_extracted_titles\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._search_arxiv_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._search_arxiv_node] End    Execution Time: 10.1428 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 0\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time: 20.8267 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.1110 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error checking GitHub URL https://github.com/yunshengtian/BE-CBO1: 404 Client Error: Not Found for url: https://github.com/yunshengtian/BE-CBO1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time: 14.6130 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  8.5151 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] End    Execution Time: 11.7161 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 2\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  1.6357 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0002 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 3\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  1.9201 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0002 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 4\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  3.5834 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  3.1613 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] End    Execution Time: 11.2579 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 5\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  2.2254 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0003 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 6\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  3.0049 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  1.7700 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] End    Execution Time:  9.5461 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 7\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  2.5862 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0956 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error checking GitHub URL https://github.com/wangronin/HVI-distributionet: 404 Client Error: Not Found for url: https://github.com/wangronin/HVI-distributionet\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  2.7583 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  4.8840 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] End    Execution Time:  9.7875 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 9\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  4.6637 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  3.3610 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_base_paper_node] End    Execution Time: 10.9083 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._base_select_best_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._base_select_best_paper_node] End    Execution Time:  6.9796 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._generate_queries_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._generate_queries_node] End    Execution Time:  2.8917 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._add_web_scrape_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Executing FireCrawl API scraping...\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://icml.cc/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://iclr.cc/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 500 Internal Server Error\"\n",
            "[ERROR] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Attempt 1 failed with HTTP error: Server error '500 Internal Server Error' for url 'https://api.firecrawl.dev/v1/scrape'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Retrying in 1 seconds...\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://icml.cc/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://iclr.cc/virtual/2024/papers.html?filter=title&search=Bayesian+optimization\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title&search=Gaussian+processes\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://icml.cc/virtual/2024/papers.html?filter=title&search=Gaussian+processes\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://iclr.cc/virtual/2024/papers.html?filter=title&search=Gaussian+processes\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title&search=model+complexity\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://icml.cc/virtual/2024/papers.html?filter=title&search=model+complexity\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://iclr.cc/virtual/2024/papers.html?filter=title&search=model+complexity\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title&search=expected+improvement\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://icml.cc/virtual/2024/papers.html?filter=title&search=expected+improvement\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://iclr.cc/virtual/2024/papers.html?filter=title&search=expected+improvement\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://cvpr.thecvf.com/virtual/2024/papers.html?filter=title&search=lengthscale+priors\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://icml.cc/virtual/2024/papers.html?filter=title&search=lengthscale+priors\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Scraping URL: https://iclr.cc/virtual/2024/papers.html?filter=title&search=lengthscale+priors\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 500 Internal Server Error\"\n",
            "[ERROR] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Attempt 1 failed with HTTP error: Server error '500 Internal Server Error' for url 'https://api.firecrawl.dev/v1/scrape'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.web_scrape_node: Retrying in 1 seconds...\n",
            "[INFO] httpx: HTTP Request: POST https://api.firecrawl.dev/v1/scrape \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._add_web_scrape_node] End    Execution Time: 203.7108 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_paper_title_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_paper_title_node] End    Execution Time: 196.5154 seconds\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: check_extracted_titles\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._search_arxiv_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._search_arxiv_node] End    Execution Time:  4.8960 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 0\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.retrieve_arxiv_text_node: Loaded text from /content/researchgraph/data/20250404_035942/papers/2310.15351v2.txt\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  0.0032 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0002 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 1\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  4.8985 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  3.1581 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] End    Execution Time:  9.1527 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 2\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.retrieve_arxiv_text_node: Loaded text from /content/researchgraph/data/20250404_035942/papers/2311.03760v3.txt\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  0.0019 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0002 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 3\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  1.1817 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0002 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 4\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.retrieve_arxiv_text_node: Loaded text from /content/researchgraph/data/20250404_035942/papers/2402.02229v5.txt\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  0.0019 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  6.3979 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] End    Execution Time: 14.3743 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 5\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.retrieve_arxiv_text_node: Loaded text from /content/researchgraph/data/20250404_035942/papers/2311.02213v2.txt\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  0.0031 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  3.8784 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] End    Execution Time: 12.8892 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 6\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.retrieve_arxiv_text_node: Loaded text from /content/researchgraph/data/20250404_035942/papers/2402.02111v2.txt\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  0.0024 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  1.8146 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._summarize_add_paper_node] End    Execution Time:  9.1498 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 7\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.retrieve_arxiv_text_node: Loaded text from /content/researchgraph/data/20250404_035942/papers/2402.07692v2.txt\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  0.0022 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.1123 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 8\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.nodes.retrieve_arxiv_text_node: Loaded text from /content/researchgraph/data/20250404_035942/papers/1912.05686v2.txt\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  0.0030 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0002 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] Start\n",
            "[INFO] researchgraph.retrieve_paper_subgraph.retrieve_paper_subgraph: process_index: 9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error checking GitHub URL https://github.com/yunshengtian/BE-CBO1: 404 Client Error: Not Found for url: https://github.com/yunshengtian/BE-CBO1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._retrieve_arxiv_full_text_node] End    Execution Time:  1.0246 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._extract_github_url_node] End    Execution Time:  0.0001 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._add_select_best_paper_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph._add_select_best_paper_node] End    Execution Time:  9.4098 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [retrieve_paper_subgraph]                End    Execution Time: 789.1038 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [generator_subgraph]                     Start\n",
            "[INFO] researchgraph.utils.execution_timers: [generator_subgraph._generator_node]     Start\n",
            "[INFO] researchgraph.generator_subgraph.generator_subgraph: ---GeneratorSubgraph---\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [generator_subgraph._generator_node]     End    Execution Time: 16.6645 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [generator_subgraph]                     End    Execution Time: 16.6709 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph]             Start\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._generate_advantage_criteria_node] Start\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._retrieve_code_with_devin_node] Start\n",
            "[INFO] researchgraph.experimental_plan_subgraph.experimental_plan_subgraph: ---ExperimentalPlanSubgraph---\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/sessions\n",
            "[INFO] researchgraph.utils.api_request_handler: API request successful on attempt 1.\n",
            "[INFO] researchgraph.experimental_plan_subgraph.nodes.retrieve_code_with_devin: Successfully created Devin session.\n",
            "[INFO] researchgraph.experimental_plan_subgraph.nodes.retrieve_code_with_devin: Devin URL: https://app.devin.ai/sessions/49790aecb38c400ca2aae86785276b0d\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._retrieve_code_with_devin_node] End    Execution Time:  0.9315 seconds\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._generate_advantage_criteria_node] End    Execution Time:  7.7579 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._check_devin_completion_node] Start\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-49790aecb38c400ca2aae86785276b0d\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 10 seconds... (Attempt 1)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 20 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-49790aecb38c400ca2aae86785276b0d\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 20 seconds... (Attempt 2)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 40 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-49790aecb38c400ca2aae86785276b0d\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 40 seconds... (Attempt 3)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-49790aecb38c400ca2aae86785276b0d\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 4)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-49790aecb38c400ca2aae86785276b0d\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 5)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-49790aecb38c400ca2aae86785276b0d\n",
            "[INFO] researchgraph.utils.api_request_handler: API request successful on attempt 6.\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._check_devin_completion_node] End    Execution Time: 362.5319 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._generate_experiment_details_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._generate_experiment_details_node] End    Execution Time: 21.7621 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._generate_experiment_code_node] Start\n",
            "[INFO] httpx: HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph._generate_experiment_code_node] End    Execution Time: 26.1768 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [experimental_plan_subgraph]             End    Execution Time: 418.2550 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [executor_subgraph]                      Start\n",
            "[INFO] researchgraph.utils.execution_timers: [executor_subgraph._generate_code_with_devin_node] Start\n",
            "[INFO] researchgraph.executor_subgraph.executor_subgraph: ---ExecutorSubgraph---\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/sessions\n",
            "[INFO] researchgraph.utils.api_request_handler: API request successful on attempt 1.\n",
            "[INFO] researchgraph.executor_subgraph.nodes.generate_code_with_devin: Successfully created Devin session.\n",
            "[INFO] researchgraph.executor_subgraph.nodes.generate_code_with_devin: Devin URL: https://app.devin.ai/sessions/f6f11b97a9254c30895bc08df6d11c3e\n",
            "[INFO] researchgraph.utils.execution_timers: [executor_subgraph._generate_code_with_devin_node] End    Execution Time:  1.1985 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [executor_subgraph._check_devin_completion_node] Start\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-f6f11b97a9254c30895bc08df6d11c3e\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 10 seconds... (Attempt 1)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 20 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-f6f11b97a9254c30895bc08df6d11c3e\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 20 seconds... (Attempt 2)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 40 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-f6f11b97a9254c30895bc08df6d11c3e\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 40 seconds... (Attempt 3)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-f6f11b97a9254c30895bc08df6d11c3e\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 4)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-f6f11b97a9254c30895bc08df6d11c3e\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 5)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.devin.ai/v1/session/devin-f6f11b97a9254c30895bc08df6d11c3e\n",
            "[INFO] researchgraph.utils.api_request_handler: API request successful on attempt 6.\n",
            "[INFO] researchgraph.utils.execution_timers: [executor_subgraph._check_devin_completion_node] End    Execution Time: 250.0658 seconds\n",
            "[INFO] researchgraph.utils.execution_timers: [executor_subgraph._execute_github_actions_workflow_node] Start\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[INFO] researchgraph.utils.api_request_handler: API request successful on attempt 1.\n",
            "[INFO] researchgraph.executor_subgraph.nodes.execute_github_actions_workflow: Successfully retrieved information on Github actions prior to execution of workflow.\n",
            "[INFO] researchgraph.executor_subgraph.nodes.execute_github_actions_workflow: Number of workflow runs before execution:0\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/workflows/run_experiment.yml/dispatches\n",
            "[WARNING] researchgraph.utils.api_request_handler: Error during API request: 422 Client Error: Unprocessable Entity for url: https://api.github.com/repos/auto-res2/auto-research/actions/workflows/run_experiment.yml/dispatches\n",
            "[INFO] researchgraph.utils.api_request_handler: API request successful on attempt 1.\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 10 seconds... (Attempt 1)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 20 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 20 seconds... (Attempt 2)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 40 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 40 seconds... (Attempt 3)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 4)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 5)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 6)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 7)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 8)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 9)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 10)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 11)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 12)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 13)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 14)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 15)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 16)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 17)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 18)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 19)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 20)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 21)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 22)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 23)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 24)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 25)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 26)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 27)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 28)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 29)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 30)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 31)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 32)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 33)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 34)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 35)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 36)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 37)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 38)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 39)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 40)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 41)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 42)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 43)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 44)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 45)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 46)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 47)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 48)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 49)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[INFO] researchgraph.utils.api_request_handler: Requests to endpoints:https://api.github.com/repos/auto-res2/auto-research/actions/runs\n",
            "[WARNING] researchgraph.utils.api_request_handler: Condition not met, retrying in 60 seconds... (Attempt 50)\n",
            "[INFO] researchgraph.utils.api_request_handler: Retrying in 60 seconds...\n",
            "[WARNING] researchgraph.utils.api_request_handler: Max retries reached. API request failed.\n",
            "[INFO] researchgraph.executor_subgraph.nodes.execute_github_actions_workflow: Successfully retrieved information on Github actions after execution of workflow.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2963d8a80638>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result = research_graph.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"recursion_limit\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2689\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2338\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2339\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2340\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2341\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/researchgraph/src/researchgraph/utils/execution_timers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(state, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{header} Start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/researchgraph/src/researchgraph/research_graph.py\u001b[0m in \u001b[0;36mexecutor_subgraph\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mmax_code_fix_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_code_fix_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             ).build_graph()\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# Writer Subgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2689\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2338\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2339\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2340\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2341\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/researchgraph/src/researchgraph/utils/execution_timers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, state, *args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{header} Start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/researchgraph/src/researchgraph/executor_subgraph/executor_subgraph.py\u001b[0m in \u001b[0;36m_execute_github_actions_workflow_node\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExecutorSubgraphState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     ) -> dict:\n\u001b[0;32m--> 115\u001b[0;31m         workflow_run_id = execute_github_actions_workflow(\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mgithub_owner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgithub_owner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mrepository_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/researchgraph/src/researchgraph/executor_subgraph/nodes/execute_github_actions_workflow.py\u001b[0m in \u001b[0;36mexecute_github_actions_workflow\u001b[0;34m(github_owner, repository_name, branch_name)\u001b[0m\n\u001b[1;32m    148\u001b[0m         )\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mworkflow_run_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_workflow_run_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_after_execution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mworkflow_run_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/researchgraph/src/researchgraph/executor_subgraph/nodes/execute_github_actions_workflow.py\u001b[0m in \u001b[0;36m_parse_workflow_run_id\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mworkflow_timestamp_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mlatest_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtzinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimezone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"workflow_runs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mcreated_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromisoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"+00:00\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mworkflow_timestamp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "result = research_graph.invoke(\n",
        "    input = input_data,\n",
        "    config={\"recursion_limit\": 500}\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}